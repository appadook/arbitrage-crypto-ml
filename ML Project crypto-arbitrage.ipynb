{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N9NDsRxW57Ki"
      },
      "source": [
        "# Machine Learning -- Crypto Arbitrage Analysis\n",
        "This notebook investigates the use of machine learning and data mining techniques to predict arbitrage opportunities in cryptocurrency markets. Using data collected through CoinAPI & XChangeAPI websockets, this research is part of my senior thesis project in Economics on \"Arbitrage in the cryptocurrency market\".\n",
        "\n",
        "## DATASET\n",
        "The dataset tracks the price of Bitcoin and Ethereum across multiple exchanges (Coinbase, Binance, Kraken, Bitstamp) and fiat currency markets (USD, EUR, GBP) along with exchange rates. It includes computed arbitrage percentages, execution strategies, and profit calculations after accounting for exchange fees.\n",
        "\n",
        "## SOURCE\n",
        "Data was collected via websockets over a 5-day period (May 22-26, 2025) and stored in CSV files.\n",
        "\n",
        "## Research Goals\n",
        "- Classify the most profitable arbitrage strategy route based on current market conditions\n",
        "- Predict whether the next timestamp will present a profitable arbitrage opportunity\n",
        "- Identify if price points in specific markets are diverging from or converging to cross-market means\n",
        "- Evaluate how vulnerable arbitrage opportunities are to latency risks\n",
        "\n",
        "## DATASET SCALE\n",
        "    28,006,444 instances\n",
        "    17 raw features + 4 transformation features\n",
        "\n",
        "## Focus and Scope\n",
        "- *Although the original data contains multiple fiat currencies, this analysis focuses on USD markets only (COINBASE_USD, BINANCE_USD, etc.)*\n",
        "- *While the dataset contains both ETH and BTC data, this notebook focuses exclusively on Bitcoin*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 347
        },
        "id": "bhIp3L786ASM",
        "outputId": "ee2ffbe5-ab29-4625-a022-8849898c2105"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "\n",
        "missing_values = [\"?\"]\n",
        "\n",
        "df0 = pd.read_csv(\"data/crypto_arbitrage_3_2025-05-22.csv\",\n",
        "                        #   names=labels,\n",
        "                          na_values = missing_values,\n",
        "                          skipinitialspace=True)\n",
        "\n",
        "df1 = pd.read_csv(\"data/crypto_arbitrage_3_2025-05-23.csv\",\n",
        "                        #   names=labels,\n",
        "                          na_values = missing_values,\n",
        "                          skipinitialspace=True)\n",
        "\n",
        "df2 = pd.read_csv(\"data/crypto_arbitrage_3_2025-05-24.csv\",\n",
        "                        #   names=labels,\n",
        "                          na_values = missing_values,\n",
        "                          skipinitialspace=True)\n",
        "\n",
        "df3 = pd.read_csv(\"data/crypto_arbitrage_3_2025-05-25.csv\",\n",
        "                        #   names=labels,\n",
        "                          na_values = missing_values,\n",
        "                          skipinitialspace=True)\n",
        "\n",
        "df4 = pd.read_csv(\"data/crypto_arbitrage_3_2025-05-26.csv\",\n",
        "                        #   names=labels,\n",
        "                          na_values = missing_values,\n",
        "                          skipinitialspace=True)\n",
        "\n",
        "\n",
        "df = pd.concat([df0, df1, df2, df3, df4], ignore_index=True)\n",
        "\n",
        "pre_rows,pre_cols = df.shape\n",
        "print(\"This is the crypto-currency data set. It has\", pre_rows, \"instances, and it has\", pre_cols, \"features.\\n\\n\")\n",
        "\n",
        "# Show the head of the data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Loading and Initial Exploration\n",
        "Loading the dataset from five separate CSV files covering a 5-day period (May 22-26, 2025). Each file contains cryptocurrency price data from different exchanges and arbitrage-related information. We'll concatenate these files into a single dataframe for analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop all rows with ETH in the crypto column\n",
        "pre_rows, pre_cols = df.shape\n",
        "\n",
        "df = df[df[\"crypto\"] != \"ETH\"]\n",
        "\n",
        "\n",
        "print(\"Before dropping all rows with ETH in the crypto column, the data set has\", pre_rows, \"instances, and it has\", pre_cols, \"features.\\n\\n\")\n",
        "\n",
        "print(\"\\n\\nAfter dropping all rows with ETH in the crypto column, the data set has\", df.shape[0], \"instances, and it has\", df.shape[1], \"features.\\n\\n\")\n",
        "\n",
        "percent_lost = (pre_rows - df.shape[0]) / pre_rows * 100\n",
        "print(f\"{percent_lost:.2f}% of the dataset was lost after dropping all ETH rows.\\n\")\n",
        "\n",
        "# Dropping the crypto column since all rows are for BTC only\n",
        "df.drop(columns=[\"crypto\"], inplace=True)\n",
        "\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Filtering to Bitcoin-Only Data\n",
        "As mentioned earlier, we'll focus exclusively on Bitcoin data by filtering out all Ethereum (ETH) records. After filtering, we'll drop the 'crypto' column since all remaining records will be for Bitcoin only."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 554
        },
        "id": "0OsrIFO_6FD8",
        "outputId": "30bc9288-3da9-49a7-e12c-427b8cf80a87"
      },
      "outputs": [],
      "source": [
        "df.dtypes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0DldiSMW6L3G"
      },
      "source": [
        "## Doing some Data analysis\n",
        "\n",
        "Looking over the missing data instances for each feature"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 663
        },
        "id": "zOxQinn86Nub",
        "outputId": "6fb9cd53-b04a-441c-9a79-52b6aaf23407"
      },
      "outputs": [],
      "source": [
        "# Plot missing data\n",
        "import missingno as msno\n",
        "\n",
        "msno.matrix(df)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_00LXCkTcd5F"
      },
      "source": [
        "## Missing data analysis\n",
        "Based on the missing data analysis, the BINANACE_GBP feature never has a single value and therefore can easily be dropped as it provides no contribution to the analysis. Additionally, based on the nature of the data collection, we can also safely remove all rows with an NA value after dropping the BINANCE_GBP feature since the missing values will only occur in the start of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FpFk7ldw6SSE",
        "outputId": "3bf49142-65c6-4033-b006-70bb7107fd5f"
      },
      "outputs": [],
      "source": [
        "# Dropping the BINANCE_GBP feaure from the data set\n",
        "pre_rows, pre_cols = df.shape\n",
        "\n",
        "df = df.drop(columns=['BINANCE_GBP'])\n",
        "\n",
        "\n",
        "print(\"\\nDropping all instances with NaN values\\n\")\n",
        "\n",
        "df = df.dropna()\n",
        "post_rows,post_cols = df.shape\n",
        "df_per = (pre_rows - post_rows) / pre_rows * 100\n",
        "\n",
        "print(\"After dropping NaN values, the data set has\", post_rows, \"instances, and it has\", post_cols, \"features.\\n\")\n",
        "print(\"This means that\", round(df_per, 2), \"% of the data was dropped.\\n\")\n",
        "# Show the head of the cleaned data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G6TX3x0p60LW",
        "outputId": "a0dcb6f7-4b99-4f7e-8cbd-4119edaadf6b"
      },
      "outputs": [],
      "source": [
        "df.info()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data Structure and Types\n",
        "Checking the data types and structure to ensure all features are properly formatted before proceeding with further analysis."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "BnEy5peN614C",
        "outputId": "43cec833-57a7-4c66-ab1c-03f41c3c6b41"
      },
      "outputs": [],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Statistical Summary\n",
        "Generating descriptive statistics for all features to understand their distributions, ranges, and central tendencies. This will help identify outliers and understand the scale of our cryptocurrency price data."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Drop non-USD columns\n",
        "Since we are working with only USD price points, the arbitrage module is limited to only exchange arbitrage and thus we can drop all the non-USD columns from the dataset\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "non_usd_columns = [column for column in df.columns if column.endswith('_GBP') or column.endswith('_EUR')]\n",
        "print(\"\\nThe following columns are not in USD:\\n\")\n",
        "for column in non_usd_columns:\n",
        "    print(column)\n",
        "\n",
        "df = df.drop(columns=non_usd_columns)\n",
        "print(\"\\nDropping the non-USD columns\\n\")\n",
        "print(\"After dropping the non-USD columns, the data set has\", df.shape[0], \"instances, and it has\", df.shape[1], \"features.\\n\")\n",
        "# Show the head of the cleaned data\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Drop the exchange rate columns for EUR/USD and GBP/USD\n",
        "df = df.drop(columns=['EUR_RATE/USD', 'GBP_RATE/USD', 'USD_RATE/USD'])\n",
        "print(\"\\nDropping the EUR_USD and GBP_USD columns\\n\")\n",
        "print(\"After dropping the EUR_USD and GBP_USD columns, the data set has\", df.shape[0], \"instances, and it has\", df.shape[1], \"features.\\n\")\n",
        "# Show the head of the cleaned data\n",
        "df.head()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Data cleaning\n",
        "Replacing all the previously trasnformed columns with new ones that extend to only the scope of this experiment which is exchange only arbitrage\n",
        "Replacing all object integers with \\$ to an int by removing the \\$"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from fee_calc import FeeCalculator\n",
        "\n",
        "def get_min_max_prices_row(row, columns):\n",
        "    \"\"\"\n",
        "    Given a row (Series) and a list of columns, return the lowest price, highest price,\n",
        "    and their respective column names (exchange only, without '_USD').\n",
        "\n",
        "    Returns:\n",
        "        min_price (float): The lowest price value.\n",
        "        min_col (str): The exchange name with the lowest price.\n",
        "        max_price (float): The highest price value.\n",
        "        max_col (str): The exchange name with the highest price.\n",
        "    \"\"\"\n",
        "    prices = row[columns]\n",
        "    min_col = prices.idxmin()\n",
        "    min_price = prices[min_col]\n",
        "    max_col = prices.idxmax()\n",
        "    max_price = prices[max_col]\n",
        "    # Only keep the exchange name before '_USD'\n",
        "    min_col_short = min_col.split('_USD')[0]\n",
        "    max_col_short = max_col.split('_USD')[0]\n",
        "    return {\n",
        "        \"min_price\": min_price,\n",
        "        \"min_col\": min_col_short,\n",
        "        \"max_price\": max_price,\n",
        "        \"max_col\": max_col_short\n",
        "    }\n",
        "\n",
        "def calculate_arbitrage(row):\n",
        "    \"\"\"\n",
        "    Calculate arbitrage opportunity and fees for a given row of data\n",
        "    \n",
        "    Args:\n",
        "        row: DataFrame row containing price data for different exchanges\n",
        "    \n",
        "    Returns:\n",
        "        Dictionary with arbitrage details: strategy, arbitrage percentage, total fees, \n",
        "        and arbitrage after fees\n",
        "    \"\"\"\n",
        "    # Get USD price columns\n",
        "    usd_columns = [col for col in row.index if col.endswith('_USD')]\n",
        "    \n",
        "    # Get min and max prices\n",
        "    price_info = get_min_max_prices_row(row, usd_columns)\n",
        "    \n",
        "    # Extract values\n",
        "    min_price = price_info[\"min_price\"]\n",
        "    min_exchange = price_info[\"min_col\"]\n",
        "    max_price = price_info[\"max_price\"]\n",
        "    max_exchange = price_info[\"max_col\"]\n",
        "    \n",
        "    # Calculate raw arbitrage (before fees)\n",
        "    raw_arbitrage = max_price - min_price\n",
        "    arbitrage_pct = (raw_arbitrage / min_price) * 100\n",
        "    \n",
        "    \n",
        "    # Initialize fee calculator\n",
        "    # Using 1 BTC as standard amount for calculation\n",
        "    crypto_amount = 1.0\n",
        "    \n",
        "    fee_calc = FeeCalculator(\n",
        "        exchange_buy=min_exchange,\n",
        "        exchange_sell=max_exchange,\n",
        "        crypto=\"BTC\",\n",
        "        crypto_amount=crypto_amount,\n",
        "        crypto_price_buy=min_price,\n",
        "        crypto_price_sell=max_price,\n",
        "        currency_withdrawal=\"USD\",\n",
        "        exchange_rates={\"USD\": 1.0}  # Not needed for USD-only calculations\n",
        "    )\n",
        "    \n",
        "    # Calculate fees\n",
        "    fees = fee_calc.calculate_fees()\n",
        "    \n",
        "    # Construct strategy string: BUY@exchange1->SELL@exchange2\n",
        "    strategy = f\"BUY@{min_exchange}->SELL@{max_exchange}\"\n",
        "    \n",
        "    return {\n",
        "        \"strategy\": strategy if fees[\"arbitrage_after_fees\"] > 0 else \"No profitable arbitrage\",\n",
        "        \"arbitrage(%)\": arbitrage_pct,\n",
        "        \"total_fees\": fees[\"total_fees\"],\n",
        "        \"arbitrage_after_fees\": fees[\"arbitrage_after_fees\"]\n",
        "    }"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Arbitrage Calculation Functions\n",
        "\n",
        "These helper functions are used to identify arbitrage opportunities between different exchanges:\n",
        "\n",
        "1. `get_min_max_prices_row`: Identifies which exchange has the lowest and highest prices for a given cryptocurrency\n",
        "2. `calculate_arbitrage`: Computes the potential profit from an arbitrage opportunity, accounting for all fees\n",
        "\n",
        "These calculations form the foundation of our prediction task - we want to predict which arbitrage strategy (which pair of exchanges) will be most profitable in the next time period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Since each row reflects a new heartbeat from the websocket, there are multiple rows with the same timestamp exact to the milisecond, which really is counter intuitive when looking at a new feature such as change in price or even some variable_(t+1). Hence, some cleaning needs to be done by essentially only keeping the last row that appears in the dataset for each unique timestamp."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "\n",
        "pre_dedup_count = len(df)\n",
        "\n",
        "df = df.drop_duplicates(subset=['timestamp'], keep='last')\n",
        "\n",
        "post_dedup_count = len(df)\n",
        "rows_removed = pre_dedup_count - post_dedup_count\n",
        "\n",
        "print(f\"Before removing duplicate timestamps: {pre_dedup_count} rows\")\n",
        "print(f\"After keeping only the last row per timestamp: {post_dedup_count} rows\")\n",
        "print(f\"Removed {rows_removed} duplicate timestamp rows ({rows_removed/pre_dedup_count:.2%} of data)\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Timestamp Deduplication\n",
        "\n",
        "The websocket data collection process can sometimes produce multiple records with the same timestamp (to the millisecond). For time series analysis and feature engineering purposes, we need one unique record per timestamp.\n",
        "\n",
        "We'll keep only the last record for each timestamp, which represents the most recent state of the market at that exact moment."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Removing the un-raw data\n",
        "df = df.drop(columns=['strategy', 'arbitrage', 'total_fees', 'arbitrage_after_fees'])\n",
        "\n",
        "df.to_csv(\"cleaned_crypto_arbitrage_intermediate.csv\", index=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Saving Intermediate Cleaned Data\n",
        "\n",
        "After performing initial data cleaning, we'll save this intermediate dataset to disk. This allows us to quickly reload the cleaned data for future analysis without repeating the cleaning steps."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df = pd.read_csv(\"cleaned_crypto_arbitrage_with_fees.csv\")\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Loading Pre-processed Data with Fee Calculations\n",
        "\n",
        "Rather than recalculating all arbitrage metrics and fees in this notebook, we're loading a pre-processed version of the dataset that already includes these calculations. This file was likely created in a separate process using the `fee_calc.py` module."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Create a new feature for if arbitrage is profitable or not\n",
        "\n",
        "# df['Profitable'] = df['arbitrage_after_fees'] > 0\n",
        "\n",
        "# # Apply the condition row by row using numpy.where\n",
        "# df['profitable_strategy'] = np.where(df['Profitable'], df['strategy'], 'None')\n",
        "\n",
        "# Extract the strategy in the next timestamp (recompute after updating strategy)\n",
        "df['next_strategy'] = df['strategy'].shift(-1)\n",
        "\n",
        "\n",
        "# Display a sample of the results\n",
        "# print(\"\\nSample of rows with profitable arbitrage:\")\n",
        "# sample_profitable = df[df['Profitable']].sample(min(5, len(df[df['Profitable']])))\n",
        "# print(sample_profitable[['strategy', 'arbitrage(%)', 'total_fees', 'arbitrage_after_fees']])\n",
        "\n",
        "\n",
        "# remove the \"$\" from the arbitrage_after_fees column\n",
        "df['arbitrage_after_fees'] = df['arbitrage_after_fees'].replace({'\\$': ''}, regex=True).astype(float)\n",
        "\n",
        "df['arbitrage(%)'] = df['arbitrage(%)'].replace({'\\%': ''}, regex=True).astype(float)\n",
        "\n",
        "df['total_fees'] = df['total_fees'].replace({'\\$': ''}, regex=True).astype(float)\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating Target Variable and Cleaning String Formats\n",
        "\n",
        "In this step, we're preparing our target variable for prediction:\n",
        "\n",
        "1. Creating 'next_strategy' column by shifting the 'strategy' column to represent the arbitrage strategy in the subsequent time period\n",
        "2. Cleaning string formatting by removing currency symbols ($ and %) to convert to proper numeric data types\n",
        "\n",
        "The 'next_strategy' column will be our target variable for the classification task - we want to predict which arbitrage strategy will be optimal in the next time period."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Data Analysis of the distribution of strategies"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Count the frequency of each strategy value\n",
        "strategy_counts = df['strategy'].value_counts(dropna=False)\n",
        "print(\"\\nStrategy counts:\\n\", strategy_counts)\n",
        "# Set up the plot style\n",
        "\n",
        "# Plot as a bar chart\n",
        "plt.figure(figsize=(12,6))\n",
        "strategy_counts.plot(kind='bar')\n",
        "plt.xlabel('Strategy')\n",
        "plt.ylabel('Frequency')\n",
        "plt.title('Frequency of Different Strategy Values')\n",
        "plt.xticks(rotation=45, ha='right')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Label Encoding & Transformation\n",
        "- Deriving different date, time, day and hour features from the timestamp\n",
        "- Deriving a boolean feature if the arbitrage after fees is profitable or not\n",
        "- Derive feature for the strategy -> the strategy being the strategy if the arbitrage_after_fees > 0\n",
        "- Normalize all prices to USD but keep the tag to know which market the price point came from\n",
        "- Extract the variance of the the following\n",
        "    - variance in exchange from the last 30 timestamps\n",
        "    - variance in fiat currency from the last 30 timestamps\n",
        "- Extract the change in price for each price point\n",
        "- ! Replace the strategy feature to capture only exchange arbitrage -- use external modules to calculate the arbitrage along with arbitrage after fees aswell as total fees again for this new condition !\n",
        "- Encode the next strategy in it's own feature. Hence Strategy_t+1\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Encode the Timestamp column to datetime and create a feature for the hour, minute, and day of the week\n",
        "df['timestamp'] = pd.to_datetime(df['timestamp'])\n",
        "df['Hour'] = df['timestamp'].dt.hour\n",
        "df['Minute'] = df['timestamp'].dt.minute\n",
        "df['DayOfWeek'] = df['timestamp'].dt.dayofweek\n",
        "# Drop the original Timestamp column\n",
        "df = df.drop(columns=['timestamp'])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# # -----------This cell does not need to be run for this smaller version of the experiment with exchange only arbitrage-----------\n",
        "\n",
        "# # Convert all price points to USD\n",
        "# # For USD prices, no conversion needed\n",
        "# # For EUR prices, multiply by EUR_RATE/USD\n",
        "# # For GBP prices, multiply by GBP_RATE/USD\n",
        "\n",
        "# # COINBASE conversions\n",
        "# df['COINBASE_EUR_USD'] = df['COINBASE_EUR'] * df['EUR_RATE/USD']\n",
        "# df['COINBASE_GBP_USD'] = df['COINBASE_GBP'] * df['GBP_RATE/USD']\n",
        "\n",
        "# # BINANCE conversions\n",
        "# df['BINANCE_EUR_USD'] = df['BINANCE_EUR'] * df['EUR_RATE/USD']\n",
        "# df['BINANCE_GBP_USD'] = df['BINANCE_GBP'] * df['GBP_RATE/USD']\n",
        "\n",
        "# # KRAKEN conversions\n",
        "# df['KRAKEN_EUR_USD'] = df['KRAKEN_EUR'] * df['EUR_RATE/USD']\n",
        "# df['KRAKEN_GBP_USD'] = df['KRAKEN_GBP'] * df['GBP_RATE/USD']\n",
        "\n",
        "# # BITSTAMP conversions\n",
        "# df['BITSTAMP_EUR_USD'] = df['BITSTAMP_EUR'] * df['EUR_RATE/USD']\n",
        "# df['BITSTAMP_GBP_USD'] = df['BITSTAMP_GBP'] * df['GBP_RATE/USD']\n",
        "\n",
        "\n",
        "# df = df.rename(columns={\n",
        "#     'COINBASE_USD': 'COINBASE_USD_USD',\n",
        "#     'BINANCE_USD': 'BINANCE_USD_USD',\n",
        "#     'KRAKEN_USD': 'KRAKEN_USD_USD',\n",
        "#     'BITSTAMP_USD': 'BITSTAMP_USD_USD'\n",
        "# })"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Extract the variance across exchanges for each exchange\n",
        "df['price_volatility'] = df[['COINBASE_USD', 'BINANCE_USD', 'KRAKEN_USD', 'BITSTAMP_USD']].var(axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Calculate the change in price from previous timestamp for each exchange_usd as percentage\n",
        "df['COINBASE_USD_change_pct'] = df['COINBASE_USD'].pct_change()\n",
        "df['BINANCE_USD_change_pct'] = df['BINANCE_USD'].pct_change()   \n",
        "df['KRAKEN_USD_change_pct'] = df['KRAKEN_USD'].pct_change()\n",
        "df['BITSTAMP_USD_change_pct'] = df['BITSTAMP_USD'].pct_change()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## One Hot encoding"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df['strategy_original'] = df['strategy'].copy()\n",
        "\n",
        "# Do one hot encoding for the strategy column\n",
        "df = pd.get_dummies(df, columns=['strategy'], prefix='', prefix_sep='')\n",
        "\n",
        "# Restore the original strategy column\n",
        "df['strategy'] = df['strategy_original']\n",
        "df.drop(columns=['strategy_original'], inplace=True)\n",
        "\n",
        "# Add one hot encoding for each strategy keeping track of the streak that the strategy has been profitable\n",
        "\n",
        "strategies = df['strategy'].unique()\n",
        "\n",
        "for strategy in strategies:\n",
        "    if strategy != 'No profitable arbitrage':  # Skip the 'no arbitrage' case\n",
        "        streak_col = f\"streak_{strategy.replace('@', '_').replace('->', '_')}\"\n",
        "        df[streak_col] = 0\n",
        "\n",
        "# Calculate streaks for each strategy\n",
        "current_streaks = {strategy: 0 for strategy in strategies}\n",
        "last_strategy = None\n",
        "\n",
        "for idx, row in df.iterrows():\n",
        "    current_strategy = row['strategy']\n",
        "    \n",
        "    # Reset all other strategy streaks to 0\n",
        "    for strategy in strategies:\n",
        "        if strategy != current_strategy:\n",
        "            current_streaks[strategy] = 0\n",
        "    \n",
        "    # Increment streak for current strategy\n",
        "    current_streaks[current_strategy] = current_streaks.get(current_strategy, 0) + 1\n",
        "    \n",
        "    # Update all streak columns\n",
        "    for strategy, streak in current_streaks.items():\n",
        "        if strategy != 'No profitable arbitrage':  # Skip the 'no arbitrage' case if desired\n",
        "            streak_col = f\"streak_{strategy.replace('@', '_').replace('->', '_')}\"\n",
        "            df.loc[idx, streak_col] = streak if strategy == current_strategy else 0\n",
        "            \n",
        "    last_strategy = current_strategy\n",
        "\n",
        "\n",
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.describe(include='all')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "DQIIWHUCb52o",
        "outputId": "5eeb3f7f-fb4e-4450-8670-93e31aa410a5"
      },
      "outputs": [],
      "source": [
        "# import libraries\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import numpy as np\n",
        "\n",
        "# select numeric and bool columns from the dataframe\n",
        "tmp = df.select_dtypes(include=['number','bool'])\n",
        "\n",
        "# set figure size\n",
        "plt.figure(figsize=(15,15))\n",
        "\n",
        "# Generate a mask to onlyshow the bottom left triangle\n",
        "mask = np.triu(np.ones_like(tmp.corr(), dtype=bool))\n",
        "\n",
        "# generate heatmap\n",
        "sns.heatmap(tmp.corr(), annot=True, mask=mask, vmin=-1, vmax=1)\n",
        "plt.title('Correlation Coefficient Of Features')\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "clV0lpQ3Za9k"
      },
      "source": [
        "## Setting Up the Experiment for Model evaluation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YYlQ7kmgZaT8"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn.neural_network import MLPClassifier\n",
        "import numpy as np\n",
        "from sklearn.dummy import DummyClassifier"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "35KeYS90Zrmg"
      },
      "outputs": [],
      "source": [
        "# Drop rows with NaN values in next_strategy (first & last row)\n",
        "df = df.dropna()\n",
        "\n",
        "# price_columns = [col for col in df.columns if col.endswith('_USD')]\n",
        "\n",
        "# Drop non-numeric columns that shouldn't be in the model\n",
        "X = df.drop(columns=['next_strategy',\n",
        "                    #   'timestamp',\n",
        "                      'arbitrage(%)', 'strategy','arbitrage_after_fees',\n",
        "                    #  'Hour', 'Minute', 'DayOfWeek', \n",
        "                     'total_fees'])\n",
        "\n",
        "\n",
        "y = df['next_strategy']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Feature and Target Variable Selection\n",
        "\n",
        "Here we define our predictor variables (X) and target variable (y):\n",
        "\n",
        "- X: All numeric features excluding timestamp, strategy details, and time components\n",
        "- y: The 'next_strategy' column representing the optimal arbitrage strategy in the next time period\n",
        "\n",
        "We're also removing any rows with NaN values in the target variable, which typically occurs at the very beginning and end of the dataset."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "X.head()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Creating a Baseline Classifier Based on the previous\n",
        "To setup a Baseline, I will create a classifier model that will act as a baseline that just choses the class that appeared in the previous instance\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "class BaselinePrev:\n",
        "    def predict(self, X_test, y_test):\n",
        "        \"\"\"\n",
        "        Predicts the next strategy based on the previous row's strategy.\n",
        "        \"\"\"\n",
        "        # Use the last known strategy as the prediction for all rows\n",
        "        if len(y_test) == 0:\n",
        "            return []\n",
        "        return [y_test.iloc[-1]] * len(X_test)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TZTmf1v7ZfzB",
        "outputId": "ed238ce4-3102-4aad-b891-567dc8dc76da"
      },
      "outputs": [],
      "source": [
        "models = {\n",
        "    \"baseline\" : DummyClassifier(strategy='most_frequent', random_state=42),\n",
        "    \"baseline_prev\" : DummyClassifier(strategy='prior', random_state=42),\n",
        "    \"Random Forest\": RandomForestClassifier(n_estimators=100, class_weight='balanced', random_state=42),\n",
        "    \n",
        "    \"SVM\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('svm', SVC(kernel='rbf', C=10, probability=True, random_state=42))\n",
        "    ]),\n",
        "    \n",
        "    \"Logistic Regression\": Pipeline([\n",
        "        ('scaler', StandardScaler()),\n",
        "        ('lr', LogisticRegression(max_iter=10000, class_weight='balanced', random_state=42))\n",
        "    ]),\n",
        "    \n",
        "    \"Gradient Boosting\": GradientBoostingClassifier(\n",
        "        n_estimators=100, \n",
        "        learning_rate=0.1, \n",
        "        max_depth=5, \n",
        "        random_state=42\n",
        "    ),\n",
        "    \n",
        "#     \"Neural Network\": Pipeline([\n",
        "#         ('scaler', StandardScaler()),\n",
        "#         ('mlp', MLPClassifier(\n",
        "#             hidden_layer_sizes=(100, 50), \n",
        "#             activation='relu',\n",
        "#             solver='adam', \n",
        "#             max_iter=300,\n",
        "#             random_state=42\n",
        "#         ))\n",
        "#     ])\n",
        "}\n",
        "\n",
        "# kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# predictions = {}\n",
        "\n",
        "# for name, model in models.items():\n",
        "#     print(f\"\\nModel: {name}\")\n",
        "#     accs = []\n",
        "\n",
        "#     for train_idx, test_idx in kf.split(X, y):\n",
        "#         X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "#         y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "#         model.fit(X_train, y_train)\n",
        "#         y_pred = model.predict(X_test)\n",
        "#         acc = accuracy_score(y_test, y_pred)\n",
        "#         accs.append(acc)\n",
        "\n",
        "#         # print(y_pred[:10])\n",
        "\n",
        "#     print(f\"Mean Accuracy: {(np.mean(accs)*100):.4f}%\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Trade simulator for evaluation\n",
        "Using a trade simluator class, we are going to evaluate beyond just accuracy -- I am deciding to use a trade simulator that will essentially simulate the trade that the model suggest (with all fees encountered along the way) and keep track of the net profits/losses to report for all my models. Being accurate isn't really enough here for comparison, it comes more so down to the ability to make the most money or have the least loss.\n",
        "\n",
        "## Feature Encoding \n",
        "\n",
        "Our target variable 'next_strategy' is categorical, representing different arbitrage paths between exchanges. While we could use one-hot encoding to convert these categories into binary features, we'll treat this as a multi-class classification problem where each strategy is a distinct class.\n",
        "\n",
        "Before building models, we'll examine feature correlations to identify potential redundancies and relationships in our data."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from trade_sim import TradeSimulator\n",
        "\n",
        "trade_simulator = TradeSimulator()\n",
        "kf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name == \"baseline\":\n",
        "        continue  # Skip baseline models for trade simulation\n",
        "    print(f\"\\nModel: {name}\")\n",
        "    total_profit = 0\n",
        "    trade_count = 0\n",
        "    successful_trades = 0\n",
        "    \n",
        "    for train_idx, test_idx in kf.split(X, y):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Simulate trades for each prediction\n",
        "        for i, pred_strategy in enumerate(y_pred):\n",
        "            # Get corresponding row from X_test for this prediction\n",
        "            row_data = X_test.iloc[i]\n",
        "            \n",
        "            # Parse the strategy to get buy and sell exchanges\n",
        "            buy_exchange, sell_exchange = trade_simulator.parse_strategy(pred_strategy)\n",
        "            \n",
        "            if buy_exchange and sell_exchange:  # Only process valid strategies\n",
        "                # Get corresponding prices from the row data\n",
        "                buy_price = row_data[f\"{buy_exchange}_USD\"]\n",
        "                sell_price = row_data[f\"{sell_exchange}_USD\"]\n",
        "                \n",
        "                # Simulate the trade\n",
        "                profit = trade_simulator.simulate(pred_strategy, buy_price, sell_price)\n",
        "                total_profit += profit\n",
        "                trade_count += 1\n",
        "                \n",
        "                if profit > 0:\n",
        "                    successful_trades += 1\n",
        "    \n",
        "    # Calculate statistics\n",
        "    avg_profit_per_trade = total_profit / trade_count if trade_count > 0 else 0\n",
        "    success_rate = (successful_trades / trade_count * 100) if trade_count > 0 else 0\n",
        "    \n",
        "    print(f\"Total Profit: ${total_profit:.2f}\")\n",
        "    print(f\"Trades Executed: {trade_count}\")\n",
        "    print(f\"Profitable Trades: {successful_trades} ({success_rate:.2f}%)\")\n",
        "    print(f\"Average Profit per Trade: ${avg_profit_per_trade:.2f}\")\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Time Series Cross-Validation\n",
        "\n",
        "StratifiedKFold with shuffling is problematic for time series data like our cryptocurrency price data because:\n",
        "\n",
        "1. It breaks the temporal dependencies in the data\n",
        "2. It creates data leakage by using future data to predict past events\n",
        "3. It doesn't reflect real-world trading scenarios where you only have access to past data\n",
        "\n",
        "A more appropriate approach for time series data is to use `TimeSeriesSplit`, which respects the temporal order of the data by ensuring that validation sets are always chronologically after the training sets."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Reset the index to visualize the splits better\n",
        "df_reset = df.reset_index()\n",
        "\n",
        "# Create TimeSeriesSplit with 5 splits\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "# Visualize the time series splits\n",
        "plt.figure(figsize=(12, 8))\n",
        "for i, (train_index, test_index) in enumerate(tscv.split(df_reset)):\n",
        "    plt.scatter(df_reset.iloc[train_index].index, \n",
        "              [i + 0.5] * len(train_index), \n",
        "              c='blue', \n",
        "              marker='_', \n",
        "              lw=6,\n",
        "              label='Training Set' if i == 0 else '')\n",
        "              \n",
        "    plt.scatter(df_reset.iloc[test_index].index, \n",
        "              [i + 0.5] * len(test_index), \n",
        "              c='red', \n",
        "              marker='_', \n",
        "              lw=6,\n",
        "              label='Testing Set' if i == 0 else '')\n",
        "\n",
        "plt.yticks(range(5), ['Split {}'.format(i + 1) for i in range(5)])\n",
        "plt.xlabel('Index')\n",
        "plt.ylabel('Split')\n",
        "plt.legend(loc='best')\n",
        "plt.title('TimeSeriesSplit')\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Final Model Evaluation with Time Series Cross-Validation and Profit Simulation\n",
        "\n",
        "In this final evaluation, we combine proper time series cross-validation with realistic trade simulation to assess model performance. For each model:\n",
        "\n",
        "1. We train on chronologically ordered data using TimeSeriesSplit\n",
        "2. We evaluate both prediction accuracy and simulated trading profits\n",
        "3. We track success rate, total profits, and average profit per trade\n",
        "\n",
        "This comprehensive evaluation approach ensures we select models that not only predict the correct arbitrage strategy but also generate actual profits when trading fees and execution are taken into account."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Re-implement model evaluation and trade simulation with TimeSeriesSplit\n",
        "from trade_sim import TradeSimulator\n",
        "\n",
        "trade_simulator = TradeSimulator()\n",
        "tscv = TimeSeriesSplit(n_splits=5)\n",
        "\n",
        "model_results = {}\n",
        "\n",
        "for name, model in models.items():\n",
        "    if name == \"baseline\":\n",
        "        continue  # Skip baseline models for trade simulation\n",
        "        \n",
        "    print(f\"\\nModel: {name}\")\n",
        "    total_profit = 0\n",
        "    trade_count = 0\n",
        "    successful_trades = 0\n",
        "    accs = []\n",
        "    \n",
        "    for train_idx, test_idx in tscv.split(X):\n",
        "        X_train, X_test = X.iloc[train_idx], X.iloc[test_idx]\n",
        "        y_train, y_test = y.iloc[train_idx], y.iloc[test_idx]\n",
        "\n",
        "        model.fit(X_train, y_train)\n",
        "        y_pred = model.predict(X_test)\n",
        "        \n",
        "        # Calculate accuracy\n",
        "        acc = accuracy_score(y_test, y_pred)\n",
        "        accs.append(acc)\n",
        "        \n",
        "        # Simulate trades for each prediction\n",
        "        split_profit = 0\n",
        "        split_trades = 0\n",
        "        split_successful = 0\n",
        "        \n",
        "        for i, pred_strategy in enumerate(y_pred):\n",
        "            # Get corresponding row from X_test for this prediction\n",
        "            row_data = X_test.iloc[i]\n",
        "            \n",
        "            # Parse the strategy to get buy and sell exchanges\n",
        "            buy_exchange, sell_exchange = trade_simulator.parse_strategy(pred_strategy)\n",
        "            \n",
        "            if buy_exchange and sell_exchange:  # Only process valid strategies\n",
        "                # Get corresponding prices from the row data\n",
        "                buy_price = row_data[f\"{buy_exchange}_USD\"]\n",
        "                sell_price = row_data[f\"{sell_exchange}_USD\"]\n",
        "                \n",
        "                # Simulate the trade\n",
        "                profit = trade_simulator.simulate(pred_strategy, buy_price, sell_price)\n",
        "                total_profit += profit\n",
        "                split_profit += profit\n",
        "                trade_count += 1\n",
        "                split_trades += 1\n",
        "                \n",
        "                if profit > 0:\n",
        "                    successful_trades += 1\n",
        "                    split_successful += 1\n",
        "        \n",
        "        # Print split results\n",
        "        split_avg_profit = split_profit / split_trades if split_trades > 0 else 0\n",
        "        split_success_rate = (split_successful / split_trades * 100) if split_trades > 0 else 0\n",
        "        print(f\"Split Results - Accuracy: {acc:.4f}, Profit: ${split_profit:.2f}, Success Rate: {split_success_rate:.2f}%\")\n",
        "    \n",
        "    # Calculate overall statistics\n",
        "    avg_profit_per_trade = total_profit / trade_count if trade_count > 0 else 0\n",
        "    success_rate = (successful_trades / trade_count * 100) if trade_count > 0 else 0\n",
        "    mean_accuracy = np.mean(accs)\n",
        "    \n",
        "    print(f\"Overall Results:\")\n",
        "    print(f\"Mean Accuracy: {(mean_accuracy*100):.4f}%\") \n",
        "    print(f\"Total Profit: ${total_profit:.2f}\")\n",
        "    print(f\"Trades Executed: {trade_count}\")\n",
        "    print(f\"Profitable Trades: {successful_trades} ({success_rate:.2f}%)\")\n",
        "    print(f\"Average Profit per Trade: ${avg_profit_per_trade:.2f}\")\n",
        "\n",
        "# Save results\n",
        "    model_results[name] = {\n",
        "        'accuracy': mean_accuracy,\n",
        "        'total_profit': total_profit,\n",
        "        'trades_executed': trade_count,\n",
        "'profitable_trades': successful_trades,\n",
        "        'success_rate': success_rate,\n",
        "        'avg_profit_per_trade': avg_profit_per_trade\n",
        "    }"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.6"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
